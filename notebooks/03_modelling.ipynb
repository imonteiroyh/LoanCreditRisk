{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba27ffe0",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This notebook performs model-agnostic and model-specific feature selection and modelling on the preprocessed datasets:\n",
    "\n",
    "- Initial filters to ensure stable variables\n",
    "- ElasticNet-regularized logistic regression to shrink and select sparse linear predictors\n",
    "- XGBoost with BorutaShap to retain high-signal features using Shap-based importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83844b",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bc9e9",
   "metadata": {},
   "source": [
    "To begin, let's assume the goal of this project is to build an initial machine learning model for a company that, up until now, has relied on alternative methods to decide whom to lend money to and has managed to remain profitable. In this scenario, it is unlikely that the company has robust infrastructure in place for frequent model retraining, effective monitoring, or other advanced MLOps practices.\n",
    "\n",
    "Therefore, it is critical at this stage to filter features not only for predictive power but also for their suitability in a production environment with limited support. In particular, we should prioritize variables that are stable both across different population segments (population stability) and over time (temporal stability). A population-stable feature should behave similarly when sampled from different random groups, while a temporally stable feature should maintain consistent behavior as data evolves over different time periods (e.g., maintaining its distribution, scale, and relationship with the target).\n",
    "\n",
    "Although some unstable variables might offer additional predictive performance, initial models — especially in traditional business settings — need to focus on reliability and trust. Restricting the model to stable features lays the groundwork for sustainable deployment. More advanced versions could, in the future, incorporate riskier or less stable features once the necessary monitoring and model maintenance tools are in place to manage and mitigate any associated risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea47b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization and progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Graph analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Feature selection utilities\n",
    "from feature_engine.selection import DropConstantFeatures, DropHighPSIFeatures\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Boruta SHAP for feature selection\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "# Statistical analysis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Jupyter notebook utilities\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c360c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed_model_features.json\") as f:\n",
    "    feature_names = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db33d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data = pd.read_parquet(\"../data/lr_processed_data.parquet\")\n",
    "\n",
    "train_lr_data = lr_data[lr_data[\"dataset\"] == \"train\"]\n",
    "validation_lr_data = lr_data[lr_data[\"dataset\"] == \"validation\"]\n",
    "\n",
    "del lr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee67b3",
   "metadata": {},
   "source": [
    "Now that the data is already split into training and validation/test sets, it's important to ensure that, from this point forward, we do not accidentally use information from outside the training data — such as during feature selection or hyperparameter tuning. To help enforce this and prevent data leakage, I will implement a decorator function that makes it easier to check that we are only working with the training set whenever required. If we accidentally use a DataFrame that contains any example with dataset != 'train', we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0977c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_checker(func):\n",
    "    \"\"\"\n",
    "    Decorator to check that the DataFrame passed as the first argument contains only rows with dataset == 'train'.\n",
    "    Raises a ValueError if any rows with a different value are found.\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if len(args) > 0 and isinstance(args[0], pd.DataFrame):\n",
    "            df = args[0]\n",
    "            if \"dataset\" in df.columns:\n",
    "                if not (df[\"dataset\"] == \"train\").all():\n",
    "                    raise ValueError(\"DataFrame contains rows where dataset != 'train'\")\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7b31e",
   "metadata": {},
   "source": [
    "### Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adadee",
   "metadata": {},
   "source": [
    "In this step, we remove near-constant features, i.e., those where the predominant value occurs in more than 99.9% of the training set. Features with so little variability are unlikely to contribute meaningful information to the model and may even hinder performance by introducing noise or unnecessary complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d551fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features dropped: ['home_ownership_status_infrequent_sklearn', 'painter', 'pilot', 'stocker', 'business_loan', 'card_refi', 'cc_consolidation', 'citi', 'engagement', 'engagement_ring', 'motorcycle', 'pay_bills', 'pool', 'pool_loan', 'refinance_loan', 'restaurant', 'ring', 'small_business', 'accounts_120days_past_due']\n",
      "Features before constant filtering: 196\n",
      "Features after constant filtering: 177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "restaurant         0.999979\n",
       "engagement_ring    0.999850\n",
       "citi               0.999829\n",
       "pool_loan          0.999809\n",
       "engagement         0.999796\n",
       "ring               0.999738\n",
       "motorcycle         0.999673\n",
       "small_business     0.999540\n",
       "stocker            0.999540\n",
       "pay_bills          0.999500\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@train_data_checker\n",
    "def drop_constant_features(train_data, feature_names, tol=0.999, missing_values=\"raise\", verbose=True):\n",
    "    \"\"\"\n",
    "    Remove constant features using DropConstantFeatures from feature_engine.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : pd.DataFrame\n",
    "        Training data containing the features.\n",
    "    feature_names : list of str\n",
    "        List of feature names to check for constant values.\n",
    "    tol : float, default=0.999\n",
    "        The threshold below which variance is considered zero (features will be dropped).\n",
    "    missing_values : str, default=\"raise\"\n",
    "        How to handle missing values.\n",
    "    verbose : bool, default=True\n",
    "        If True, prints diagnostics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names_nonconst : list of str\n",
    "        Features remaining after constant feature filtering.\n",
    "    dropped_features : list of str\n",
    "        Features identified as constant.\n",
    "    selector : DropConstantFeatures\n",
    "        The fitted DropConstantFeatures object.\n",
    "    \"\"\"\n",
    "\n",
    "    selector = DropConstantFeatures(tol=tol, variables=feature_names, missing_values=missing_values)\n",
    "    selector.fit(train_data[feature_names])\n",
    "    dropped_features = selector.features_to_drop_\n",
    "    non_constant_features = [f for f in feature_names if f not in dropped_features]\n",
    "    if verbose:\n",
    "        print(\"Constant features dropped:\", dropped_features)\n",
    "        print(\"Features before constant filtering:\", len(feature_names))\n",
    "        print(\"Features after constant filtering:\", len(non_constant_features))\n",
    "    return non_constant_features, dropped_features, selector\n",
    "\n",
    "\n",
    "non_constant_features, dropped_features, selector = drop_constant_features(train_lr_data, feature_names)\n",
    "display(\n",
    "    pd.Series(\n",
    "        {feature: train_lr_data[feature].value_counts(normalize=True).iloc[0] for feature in dropped_features}\n",
    "    )\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e5d1",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56cadc",
   "metadata": {},
   "source": [
    "In the exploration notebook (01_exploration.ipynb), we briefly looked at feature correlations, but did not take corrective actions at that stage. After transforming the textual variables, it is likely that new correlated features have appeared. We will address this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1430a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>absolute_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fico_score_low</td>\n",
       "      <td>fico_score_high</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vice</td>\n",
       "      <td>vice_president</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buying</td>\n",
       "      <td>home_buying</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card_refinancing</td>\n",
       "      <td>refinancing</td>\n",
       "      <td>0.998505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>card</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.997664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home_improvement</td>\n",
       "      <td>improvement</td>\n",
       "      <td>0.997008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>moving_relocation</td>\n",
       "      <td>relocation</td>\n",
       "      <td>0.992528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car_financing</td>\n",
       "      <td>financing</td>\n",
       "      <td>0.989545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>credit</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.979812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>revolving_trades_with_balance</td>\n",
       "      <td>active_revolving_trades</td>\n",
       "      <td>0.977853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>card</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.977475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>debt</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.976122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loan_purpose_medical</td>\n",
       "      <td>medical</td>\n",
       "      <td>0.972506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>truck</td>\n",
       "      <td>truck_driver</td>\n",
       "      <td>0.969739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expenses</td>\n",
       "      <td>medical_expenses</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature_1                feature_2  \\\n",
       "0                  fico_score_low          fico_score_high   \n",
       "1                            vice           vice_president   \n",
       "2                          buying              home_buying   \n",
       "3                card_refinancing              refinancing   \n",
       "4                            card              credit_card   \n",
       "5                home_improvement              improvement   \n",
       "6               moving_relocation               relocation   \n",
       "7                   car_financing                financing   \n",
       "8                          credit              credit_card   \n",
       "9   revolving_trades_with_balance  active_revolving_trades   \n",
       "10                           card                   credit   \n",
       "11                           debt       debt_consolidation   \n",
       "12           loan_purpose_medical                  medical   \n",
       "13                          truck             truck_driver   \n",
       "14                       expenses         medical_expenses   \n",
       "\n",
       "    absolute_correlation  \n",
       "0               1.000000  \n",
       "1               1.000000  \n",
       "2               1.000000  \n",
       "3               0.998505  \n",
       "4               0.997664  \n",
       "5               0.997008  \n",
       "6               0.992528  \n",
       "7               0.989545  \n",
       "8               0.979812  \n",
       "9               0.977853  \n",
       "10              0.977475  \n",
       "11              0.976122  \n",
       "12              0.972506  \n",
       "13              0.969739  \n",
       "14              0.965517  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@train_data_checker\n",
    "def get_top_correlation_pairs(data, feature_names, sample_size=10_000, corr_method=\"kendall\"):\n",
    "    \"\"\"\n",
    "    Computes the top absolute pairwise correlations among the given features in data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input dataframe containing the features.\n",
    "    feature_names : list\n",
    "        List of features to compute correlations on.\n",
    "    sample_size : int, optional\n",
    "        If the number of rows exceeds this, a random sample is used.\n",
    "    corr_method : str, optional\n",
    "        Method for correlation, e.g., \"kendall\", \"pearson\", etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns [\"feature_1\", \"feature_2\", \"absolute_correlation\"], sorted descending by absolute_correlation.\n",
    "    \"\"\"\n",
    "\n",
    "    correlation_sample = data[feature_names].dropna()\n",
    "    if len(correlation_sample) > sample_size:\n",
    "        correlation_sample = correlation_sample.sample(n=sample_size, random_state=34)\n",
    "\n",
    "    correlation_matrix = correlation_sample.corr(method=corr_method)\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    top_correlation_pairs = (\n",
    "        upper.stack()\n",
    "        .abs()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\": \"feature_1\", \"level_1\": \"feature_2\", 0: \"absolute_correlation\"})\n",
    "    )\n",
    "\n",
    "    return top_correlation_pairs\n",
    "\n",
    "\n",
    "top_correlation_pairs = get_top_correlation_pairs(train_lr_data, non_constant_features)\n",
    "top_correlation_pairs.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b278cd",
   "metadata": {},
   "source": [
    "When reviewing the correlations, we notice that some variables appear multiple times and are often closely related to the same underlying concept (for example, `loan_purpose_home_improvement`, `home`, `improvement`, `home_improvement`, etc). To address this, we will cluster such groups of features and, from each cluster, choose a representative feature based on its correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b029267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fico_score_high, fico_score_low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vice, vice_president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[buying, home_buying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[refinancing, card_refinancing, loan_purpose_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[improvement, home, loan_purpose_home_improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[relocation, moving, moving_relocation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[financing, car_financing, car, loan_purpose_car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[revolving_trades_with_balance, active_revolvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[loan_purpose_debt_consolidation, debt, consol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[medical, expenses, loan_purpose_medical, medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[truck_driver, truck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[satisfactory_accounts_count, open_credit_lines]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[business, loan_purpose_small_business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[credit_history_age_years, earliest_credit_lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[total_current_balance, total_high_credit_limit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[accounts_currently_delinquent, accounts_30day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[project_manager, project]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[home_ownership_status_MORTGAGE, home_ownershi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features\n",
       "0                   [fico_score_high, fico_score_low]\n",
       "1                              [vice, vice_president]\n",
       "2                               [buying, home_buying]\n",
       "3   [refinancing, card_refinancing, loan_purpose_c...\n",
       "4   [improvement, home, loan_purpose_home_improvem...\n",
       "5             [relocation, moving, moving_relocation]\n",
       "6   [financing, car_financing, car, loan_purpose_car]\n",
       "7   [revolving_trades_with_balance, active_revolvi...\n",
       "8   [loan_purpose_debt_consolidation, debt, consol...\n",
       "9   [medical, expenses, loan_purpose_medical, medi...\n",
       "10                              [truck_driver, truck]\n",
       "11   [satisfactory_accounts_count, open_credit_lines]\n",
       "12            [business, loan_purpose_small_business]\n",
       "13  [credit_history_age_years, earliest_credit_lin...\n",
       "14   [total_current_balance, total_high_credit_limit]\n",
       "15  [accounts_currently_delinquent, accounts_30day...\n",
       "16                         [project_manager, project]\n",
       "17  [home_ownership_status_MORTGAGE, home_ownershi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_high_correlation_clusters(top_correlation_pairs, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Groups features into clusters where each cluster contains highly correlated features (absolute_correlation > threshold).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    top_correlation_pairs : pd.DataFrame\n",
    "        DataFrame with columns [\"feature_1\", \"feature_2\", \"absolute_correlation\"].\n",
    "    threshold : float, optional\n",
    "        Absolute correlation threshold for clustering.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns [\"features\"], each row is a cluster of highly correlated features.\n",
    "    \"\"\"\n",
    "    high_correlation_pairs = top_correlation_pairs.query(\"absolute_correlation > @threshold\")\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from(\n",
    "        high_correlation_pairs[[\"feature_1\", \"feature_2\"]].itertuples(index=False, name=None)\n",
    "    )\n",
    "    feature_clusters = [list(cluster) for cluster in nx.connected_components(graph)]\n",
    "    clusters = pd.DataFrame(\n",
    "        {\n",
    "            \"features\": feature_clusters,\n",
    "        }\n",
    "    )\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = get_high_correlation_clusters(top_correlation_pairs, threshold=0.8)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb1cb3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>feature_target_correlation</th>\n",
       "      <th>selected_feature</th>\n",
       "      <th>removed_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fico_score_high, fico_score_low]</td>\n",
       "      <td>{'fico_score_high': '-0.10', 'fico_score_low':...</td>\n",
       "      <td>fico_score_high</td>\n",
       "      <td>[fico_score_low]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vice, vice_president]</td>\n",
       "      <td>{'vice': '-0.01', 'vice_president': '-0.01'}</td>\n",
       "      <td>vice</td>\n",
       "      <td>[vice_president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[buying, home_buying]</td>\n",
       "      <td>{'buying': '0.01', 'home_buying': '0.01'}</td>\n",
       "      <td>buying</td>\n",
       "      <td>[home_buying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[refinancing, card_refinancing, loan_purpose_c...</td>\n",
       "      <td>{'loan_purpose_credit_card': '-0.04', 'card': ...</td>\n",
       "      <td>loan_purpose_credit_card</td>\n",
       "      <td>[card, card_refinancing, credit, credit_card, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[improvement, home, loan_purpose_home_improvem...</td>\n",
       "      <td>{'home': '-0.01', 'home_improvement': '-0.01',...</td>\n",
       "      <td>home</td>\n",
       "      <td>[home_improvement, improvement, loan_purpose_h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[relocation, moving, moving_relocation]</td>\n",
       "      <td>{'moving': '0.01', 'moving_relocation': '0.01'...</td>\n",
       "      <td>moving</td>\n",
       "      <td>[moving_relocation, relocation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[financing, car_financing, car, loan_purpose_car]</td>\n",
       "      <td>{'car': '-0.01', 'car_financing': '-0.01', 'fi...</td>\n",
       "      <td>car</td>\n",
       "      <td>[car_financing, financing, loan_purpose_car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[revolving_trades_with_balance, active_revolvi...</td>\n",
       "      <td>{'active_revolving_trades': '0.04', 'revolving...</td>\n",
       "      <td>active_revolving_trades</td>\n",
       "      <td>[revolving_trades_with_balance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[loan_purpose_debt_consolidation, debt, consol...</td>\n",
       "      <td>{'debt_consolidation': '0.03', 'consolidation'...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>[consolidation, debt, loan_purpose_debt_consol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[medical, expenses, loan_purpose_medical, medi...</td>\n",
       "      <td>{'expenses': '0.01', 'loan_purpose_medical': '...</td>\n",
       "      <td>expenses</td>\n",
       "      <td>[loan_purpose_medical, medical, medical_expenses]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[truck_driver, truck]</td>\n",
       "      <td>{'truck': '0.02', 'truck_driver': '0.02'}</td>\n",
       "      <td>truck</td>\n",
       "      <td>[truck_driver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[satisfactory_accounts_count, open_credit_lines]</td>\n",
       "      <td>{'open_credit_lines': '0.01', 'satisfactory_ac...</td>\n",
       "      <td>open_credit_lines</td>\n",
       "      <td>[satisfactory_accounts_count]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[business, loan_purpose_small_business]</td>\n",
       "      <td>{'business': '0.02', 'loan_purpose_small_busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>[loan_purpose_small_business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[credit_history_age_years, earliest_credit_lin...</td>\n",
       "      <td>{'credit_history_age_years': '-0.04', 'earlies...</td>\n",
       "      <td>credit_history_age_years</td>\n",
       "      <td>[earliest_credit_line_year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[total_current_balance, total_high_credit_limit]</td>\n",
       "      <td>{'total_high_credit_limit': '-0.07', 'total_cu...</td>\n",
       "      <td>total_high_credit_limit</td>\n",
       "      <td>[total_current_balance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[accounts_currently_delinquent, accounts_30day...</td>\n",
       "      <td>{'accounts_30days_past_due': '0.00', 'accounts...</td>\n",
       "      <td>accounts_30days_past_due</td>\n",
       "      <td>[accounts_currently_delinquent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[project_manager, project]</td>\n",
       "      <td>{'project': '-0.01', 'project_manager': '-0.01'}</td>\n",
       "      <td>project</td>\n",
       "      <td>[project_manager]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[home_ownership_status_MORTGAGE, home_ownershi...</td>\n",
       "      <td>{'home_ownership_status_MORTGAGE': '-0.07', 'h...</td>\n",
       "      <td>home_ownership_status_MORTGAGE</td>\n",
       "      <td>[home_ownership_status_RENT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  \\\n",
       "0                   [fico_score_high, fico_score_low]   \n",
       "1                              [vice, vice_president]   \n",
       "2                               [buying, home_buying]   \n",
       "3   [refinancing, card_refinancing, loan_purpose_c...   \n",
       "4   [improvement, home, loan_purpose_home_improvem...   \n",
       "5             [relocation, moving, moving_relocation]   \n",
       "6   [financing, car_financing, car, loan_purpose_car]   \n",
       "7   [revolving_trades_with_balance, active_revolvi...   \n",
       "8   [loan_purpose_debt_consolidation, debt, consol...   \n",
       "9   [medical, expenses, loan_purpose_medical, medi...   \n",
       "10                              [truck_driver, truck]   \n",
       "11   [satisfactory_accounts_count, open_credit_lines]   \n",
       "12            [business, loan_purpose_small_business]   \n",
       "13  [credit_history_age_years, earliest_credit_lin...   \n",
       "14   [total_current_balance, total_high_credit_limit]   \n",
       "15  [accounts_currently_delinquent, accounts_30day...   \n",
       "16                         [project_manager, project]   \n",
       "17  [home_ownership_status_MORTGAGE, home_ownershi...   \n",
       "\n",
       "                           feature_target_correlation  \\\n",
       "0   {'fico_score_high': '-0.10', 'fico_score_low':...   \n",
       "1        {'vice': '-0.01', 'vice_president': '-0.01'}   \n",
       "2           {'buying': '0.01', 'home_buying': '0.01'}   \n",
       "3   {'loan_purpose_credit_card': '-0.04', 'card': ...   \n",
       "4   {'home': '-0.01', 'home_improvement': '-0.01',...   \n",
       "5   {'moving': '0.01', 'moving_relocation': '0.01'...   \n",
       "6   {'car': '-0.01', 'car_financing': '-0.01', 'fi...   \n",
       "7   {'active_revolving_trades': '0.04', 'revolving...   \n",
       "8   {'debt_consolidation': '0.03', 'consolidation'...   \n",
       "9   {'expenses': '0.01', 'loan_purpose_medical': '...   \n",
       "10          {'truck': '0.02', 'truck_driver': '0.02'}   \n",
       "11  {'open_credit_lines': '0.01', 'satisfactory_ac...   \n",
       "12  {'business': '0.02', 'loan_purpose_small_busin...   \n",
       "13  {'credit_history_age_years': '-0.04', 'earlies...   \n",
       "14  {'total_high_credit_limit': '-0.07', 'total_cu...   \n",
       "15  {'accounts_30days_past_due': '0.00', 'accounts...   \n",
       "16   {'project': '-0.01', 'project_manager': '-0.01'}   \n",
       "17  {'home_ownership_status_MORTGAGE': '-0.07', 'h...   \n",
       "\n",
       "                  selected_feature  \\\n",
       "0                  fico_score_high   \n",
       "1                             vice   \n",
       "2                           buying   \n",
       "3         loan_purpose_credit_card   \n",
       "4                             home   \n",
       "5                           moving   \n",
       "6                              car   \n",
       "7          active_revolving_trades   \n",
       "8               debt_consolidation   \n",
       "9                         expenses   \n",
       "10                           truck   \n",
       "11               open_credit_lines   \n",
       "12                        business   \n",
       "13        credit_history_age_years   \n",
       "14         total_high_credit_limit   \n",
       "15        accounts_30days_past_due   \n",
       "16                         project   \n",
       "17  home_ownership_status_MORTGAGE   \n",
       "\n",
       "                                     removed_features  \n",
       "0                                    [fico_score_low]  \n",
       "1                                    [vice_president]  \n",
       "2                                       [home_buying]  \n",
       "3   [card, card_refinancing, credit, credit_card, ...  \n",
       "4   [home_improvement, improvement, loan_purpose_h...  \n",
       "5                     [moving_relocation, relocation]  \n",
       "6        [car_financing, financing, loan_purpose_car]  \n",
       "7                     [revolving_trades_with_balance]  \n",
       "8   [consolidation, debt, loan_purpose_debt_consol...  \n",
       "9   [loan_purpose_medical, medical, medical_expenses]  \n",
       "10                                     [truck_driver]  \n",
       "11                      [satisfactory_accounts_count]  \n",
       "12                      [loan_purpose_small_business]  \n",
       "13                        [earliest_credit_line_year]  \n",
       "14                            [total_current_balance]  \n",
       "15                    [accounts_currently_delinquent]  \n",
       "16                                  [project_manager]  \n",
       "17                       [home_ownership_status_RENT]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@train_data_checker\n",
    "def enrich_clusters_with_target_correlation(clusters, data, target_column, correlation_method=\"kendall\"):\n",
    "    \"\"\"\n",
    "    Enriches the clusters DataFrame with the correlation of each feature in the cluster with the target,\n",
    "    highlights the selected feature (with the maximum absolute correlation to target), and the features to be removed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clusters : pd.DataFrame\n",
    "        DataFrame with a \"features\" column (a list of feature names).\n",
    "    data : pd.DataFrame\n",
    "        Data containing the features and the target variable.\n",
    "    target_column : str\n",
    "        Name of the target column.\n",
    "    correlation_method : str, optional\n",
    "        Correlation method to use (default \"kendall\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - features (list of features)\n",
    "        - feature_target_corrs (dict: feature -> correlation with target)\n",
    "        - feature_target_corr_text (str: \"variable: correlation\" per line)\n",
    "        - selected_feature (feature with highest absolute correlation)\n",
    "        - removed_features (all others)\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for _, row in clusters.iterrows():\n",
    "        features = row[\"features\"]\n",
    "        correlations = {}\n",
    "        # Compute correlations for features in the cluster\n",
    "        for feat in features:\n",
    "            if feat in data.columns:\n",
    "                correlation = data[[feat, target_column]].dropna().corr(method=correlation_method).iloc[0, 1]\n",
    "                correlations[feat] = f\"{correlation:.2f}\" if correlation is not None else \"nan\"\n",
    "\n",
    "        # Order correlations first by absolute correlation (descending), then by feature name (ascending)\n",
    "        ordered_corrs = sorted(\n",
    "            correlations.items(),\n",
    "            key=lambda kv: (-(abs(float(kv[1])) if kv[1] != \"nan\" else float(\"-inf\")), kv[0]),\n",
    "        )\n",
    "        correlations = dict(ordered_corrs)\n",
    "\n",
    "        if correlations:\n",
    "            correlations_float = {\n",
    "                k: float(v) if v != \"nan\" else float(\"-inf\") for k, v in correlations.items()\n",
    "            }\n",
    "            selected_feature = max(correlations_float, key=lambda k: abs(correlations_float[k]))\n",
    "            removed_features = [f for f in correlations if f != selected_feature]\n",
    "        else:\n",
    "            selected_feature = None\n",
    "            removed_features = features\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"features\": features,\n",
    "                \"feature_target_correlation\": correlations,\n",
    "                \"selected_feature\": selected_feature,\n",
    "                \"removed_features\": removed_features,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "clusters_enriched = enrich_clusters_with_target_correlation(\n",
    "    clusters, train_lr_data, target_column=\"default_binary\", correlation_method=\"kendall\"\n",
    ")\n",
    "clusters_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a8b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 146\n"
     ]
    }
   ],
   "source": [
    "non_correlated_features = [\n",
    "    feature\n",
    "    for feature in non_constant_features\n",
    "    if feature not in sum(clusters_enriched[\"removed_features\"].tolist(), [])\n",
    "]\n",
    "print(len(non_constant_features), len(non_correlated_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099e92e",
   "metadata": {},
   "source": [
    "### Population Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f3480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high PSI drift: []\n",
      "Features before PSI filtering: 146\n",
      "Features after PSI filtering: 146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "months_since_oldest_revolving      0.166305\n",
       "percent_trades_never_delinquent    0.160886\n",
       "revolving_accounts_count           0.142899\n",
       "months_since_recent_revolving      0.134823\n",
       "average_current_balance            0.111372\n",
       "bankcard_accounts_count            0.110502\n",
       "months_since_oldest_installment    0.109317\n",
       "total_installment_credit_limit     0.108483\n",
       "total_high_credit_limit            0.101471\n",
       "bankcard_utilization               0.096442\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@train_data_checker\n",
    "def get_population_stable_features(\n",
    "    train_data, feature_names, bins=10, threshold=0.25, missing_values=\"ignore\", verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects features with high Population Stability Index (PSI) drift in train data and returns\n",
    "    a filtered list of stable feature names.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : pd.DataFrame\n",
    "        Training data containing the features.\n",
    "    feature_names : list of str\n",
    "        List of feature names to check.\n",
    "    bins : int, default=10\n",
    "        Number of bins to use for PSI calculation.\n",
    "    threshold : float, default=0.25\n",
    "        PSI threshold above which features are dropped.\n",
    "    missing_values : str, default=\"ignore\"\n",
    "        Whether to ignore missing values or handle them.\n",
    "    verbose : bool, default=True\n",
    "        If True, prints diagnostics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    population_stable_features : list of str\n",
    "        Features remaining after PSI filtering.\n",
    "    dropped_features : list of str\n",
    "        Features identified as unstable by PSI.\n",
    "    drop_psi_estimator : DropHighPSIFeatures\n",
    "        The fitted DropHighPSIFeatures object.\n",
    "    \"\"\"\n",
    "\n",
    "    drop_psi = DropHighPSIFeatures(bins=bins, threshold=threshold, missing_values=missing_values)\n",
    "    drop_psi.fit(train_data[feature_names])\n",
    "\n",
    "    drifted_features = drop_psi.features_to_drop_\n",
    "    population_stable_features = [f for f in feature_names if f not in drifted_features]\n",
    "    if verbose:\n",
    "        print(\"Features with high PSI drift:\", drifted_features)\n",
    "        print(\"Features before PSI filtering:\", len(feature_names))\n",
    "        print(\"Features after PSI filtering:\", len(population_stable_features))\n",
    "\n",
    "    return population_stable_features, drifted_features, drop_psi\n",
    "\n",
    "\n",
    "population_stable_features, drifted_features, drop_psi = get_population_stable_features(\n",
    "    train_lr_data, non_correlated_features\n",
    ")\n",
    "display(pd.Series(drop_psi.psi_values_).sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d91abf",
   "metadata": {},
   "source": [
    "Some features show notable PSI, but still at low or moderate levels, so we will keep them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de4b99",
   "metadata": {},
   "source": [
    "### Time Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac264676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stable features: ['home_ownership_status_MORTGAGE', 'home_ownership_status_OWN', 'state_AL', 'state_AZ', 'state_CA', 'state_CO', 'state_CT', 'state_FL', 'state_GA', 'state_IL', 'state_IN', 'state_LA', 'state_MA', 'state_MD', 'state_MI', 'state_MN', 'state_MO', 'state_NC', 'state_NJ', 'state_NV', 'state_NY', 'state_OH', 'state_OR', 'state_PA', 'state_SC', 'state_TN', 'state_TX', 'state_VA', 'state_WA', 'state_WI', 'state_infrequent_sklearn', 'income_verification_status_Not Verified', 'income_verification_status_Source Verified', 'income_verification_status_Verified', 'loan_purpose_credit_card', 'loan_purpose_major_purchase', 'loan_purpose_other', 'loan_purpose_infrequent_sklearn', 'accountant', 'administrator', 'analyst', 'architect', 'attorney', 'bartender', 'bus', 'business_analyst', 'cashier', 'chef', 'clerk', 'cna', 'controller', 'cook', 'dealer', 'developer', 'director', 'driver', 'engineer', 'firefighter', 'operator', 'owner', 'pastor', 'physician', 'police', 'president', 'product', 'professor', 'program_manager', 'project', 'receptionist', 'sales', 'senior', 'server', 'software', 'software_engineer', 'sr', 'systems', 'teacher', 'truck', 'university', 'vice', 'vp', 'welder', 'bills', 'business', 'buying', 'car', 'card_consolidation', 'card_debt', 'card_payoff', 'card_refinance', 'cc', 'consolidate', 'consolidation_loan', 'debt_consolidation', 'debt_free', 'expenses', 'home', 'loan', 'moving', 'payoff', 'refi', 'refinance', 'employment_length_years', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'debt_to_income_ratio', 'delinquencies_past_2years', 'delinquent_amount', 'accounts_30days_past_due', 'accounts_90plus_days_past_due_24m', 'accounts_ever_120days_past_due', 'public_records_count', 'public_records_bankruptcies', 'tax_liens_count', 'open_credit_lines', 'total_credit_lines', 'revolving_balance', 'revolving_utilization_rate', 'revolving_accounts_count', 'open_revolving_trades', 'active_revolving_trades', 'months_since_oldest_revolving', 'months_since_recent_revolving', 'installment_accounts_count', 'months_since_oldest_installment', 'total_installment_credit_limit', 'bankcard_accounts_count', 'active_bankcard_accounts', 'satisfactory_bankcard_accounts', 'bankcard_utilization', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'inquiries_last_6months', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_balance_excluding_mortgage', 'total_bankcard_limit', 'average_current_balance', 'months_since_recent_account', 'mortgage_accounts_count', 'percent_trades_never_delinquent', 'credit_history_age_years']\n",
      "Time non-stable features: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loan                                       5.785529e-09\n",
       "debt_consolidation                         2.014209e-13\n",
       "consolidation_loan                         1.061572e-17\n",
       "payoff                                     3.083373e-20\n",
       "refinance                                  1.414099e-20\n",
       "inquiries_last_6months                     4.019627e-21\n",
       "card_refinance                             9.305046e-22\n",
       "debt_to_income_ratio                       3.880561e-22\n",
       "fico_score_high                            2.681444e-22\n",
       "income_verification_status_Not Verified    7.578455e-23\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_time_stable_features(\n",
    "    data, features, sample_size=10_000, date_column=\"loan_issue_date\", verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Select features that are (reasonably) stationary over time (\"time-stable\")\n",
    "    using the Augmented Dickey-Fuller (ADF) test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input DataFrame containing the features and a date column.\n",
    "    features : list of str\n",
    "        List of feature names to check for time stability.\n",
    "    sample_size : int, default=10_000\n",
    "        The number of rows to sample from the data to speed up the computation.\n",
    "    date_column : str, default=\"loan_issue_date\"\n",
    "        The column name containing the dates used to sort the data temporally.\n",
    "    verbose : bool, default=True\n",
    "        If True, prints diagnostics about feature stationarity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stable_features : list of str\n",
    "        Features classified as stationary (p-value < 0.05).\n",
    "    nonstationary_features : list of str\n",
    "        Features classified as non-stationary (p-value >= 0.05).\n",
    "    adf_results : dict\n",
    "        Mapping of feature name to its ADF test p-value.\n",
    "    \"\"\"\n",
    "    time_sorted = data.sample(sample_size, random_state=34).sort_values(date_column)\n",
    "    stable_features = []\n",
    "    nonstationary_features = []\n",
    "    adf_results = {}\n",
    "\n",
    "    for feature in features:\n",
    "        series = time_sorted[feature].values\n",
    "        # Remove nans to avoid ADF errors\n",
    "        series = series[~pd.isnull(series)]\n",
    "        if len(series) < 10:  # skip if too short\n",
    "            continue\n",
    "        try:\n",
    "            adf_result = adfuller(series, autolag=\"AIC\")\n",
    "            pvalue = adf_result[1]\n",
    "            adf_results[feature] = pvalue\n",
    "            if pvalue < 0.1:\n",
    "                stable_features.append(feature)\n",
    "            else:\n",
    "                nonstationary_features.append(feature)\n",
    "        except Exception as e:\n",
    "            # Just skip features that error out\n",
    "            if verbose:\n",
    "                print(f\"ADF failed for {feature}: {e}\")\n",
    "            continue\n",
    "    if verbose:\n",
    "        print(\"Time stable features:\", stable_features)\n",
    "        print(\"Time non-stable features:\", nonstationary_features)\n",
    "\n",
    "    return stable_features, nonstationary_features, adf_results\n",
    "\n",
    "\n",
    "time_stable_features, time_nonstable_features, adf_results = select_time_stable_features(\n",
    "    train_lr_data, population_stable_features, date_column=\"loan_issue_date\"\n",
    ")\n",
    "display(pd.Series(adf_results).sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f2c10",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "This section describes the feature selection procedure using logistic regression with ElasticNet regularization. The goal is to identify a stable and predictive subset of features by applying a stability selection approach. Specifically, we repeatedly fit a logistic regression model with ElasticNet penalty (using stochastic gradient descent) to different subsamples of the training data. This is done across multiple cross-validation folds and bootstrap runs, controlling the strength of regularization and the relative weighting of L1 and L2 penalties.\n",
    "\n",
    "For each run, we record which features receive non-zero coefficients. At the end of all runs, we calculate for each feature the proportion of times it was selected, and retain only those features that are consistently selected above a user-defined threshold. This process helps ensure that only robust and non-redundant features are kept, improving generalizability and model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67baf79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home_ownership_status_MORTGAGE', 'home_ownership_status_OWN', 'state_AL', 'state_AZ', 'state_CA', 'state_CO', 'state_CT', 'state_FL', 'state_GA', 'state_IL', 'state_IN', 'state_LA', 'state_MA', 'state_MD', 'state_MI', 'state_MN', 'state_MO', 'state_NC', 'state_NJ', 'state_NV', 'state_NY', 'state_OH', 'state_OR', 'state_PA', 'state_SC', 'state_TN', 'state_TX', 'state_VA', 'state_WA', 'state_WI', 'state_infrequent_sklearn', 'income_verification_status_Not Verified', 'income_verification_status_Source Verified', 'income_verification_status_Verified', 'loan_purpose_credit_card', 'loan_purpose_major_purchase', 'loan_purpose_other', 'loan_purpose_infrequent_sklearn', 'accountant', 'administrator', 'analyst', 'architect', 'attorney', 'bartender', 'bus', 'business_analyst', 'cashier', 'chef', 'clerk', 'cna', 'controller', 'cook', 'dealer', 'developer', 'director', 'driver', 'engineer', 'firefighter', 'operator', 'owner', 'pastor', 'physician', 'police', 'president', 'product', 'professor', 'program_manager', 'project', 'receptionist', 'sales', 'senior', 'server', 'software', 'software_engineer', 'sr', 'systems', 'teacher', 'truck', 'university', 'vice', 'vp', 'welder', 'bills', 'business', 'buying', 'car', 'card_consolidation', 'card_debt', 'card_payoff', 'card_refinance', 'cc', 'consolidate', 'consolidation_loan', 'debt_consolidation', 'debt_free', 'expenses', 'home', 'loan', 'moving', 'payoff', 'refi', 'refinance', 'employment_length_years', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'debt_to_income_ratio', 'delinquencies_past_2years', 'delinquent_amount', 'accounts_30days_past_due', 'accounts_90plus_days_past_due_24m', 'accounts_ever_120days_past_due', 'public_records_count', 'public_records_bankruptcies', 'tax_liens_count', 'open_credit_lines', 'total_credit_lines', 'revolving_balance', 'revolving_utilization_rate', 'revolving_accounts_count', 'open_revolving_trades', 'active_revolving_trades', 'months_since_oldest_revolving', 'months_since_recent_revolving', 'installment_accounts_count', 'months_since_oldest_installment', 'total_installment_credit_limit', 'bankcard_accounts_count', 'active_bankcard_accounts', 'satisfactory_bankcard_accounts', 'bankcard_utilization', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'inquiries_last_6months', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_balance_excluding_mortgage', 'total_bankcard_limit', 'average_current_balance', 'months_since_recent_account', 'mortgage_accounts_count', 'percent_trades_never_delinquent', 'credit_history_age_years']\n"
     ]
    }
   ],
   "source": [
    "stable_features = time_stable_features\n",
    "print(stable_features)\n",
    "target = \"default_binary\"\n",
    "\n",
    "X_train_lr = train_lr_data[stable_features].to_numpy()\n",
    "X_validation_lr = validation_lr_data[stable_features].to_numpy()\n",
    "\n",
    "y_train_lr = train_lr_data[target]\n",
    "y_validation_lr = validation_lr_data[target]\n",
    "\n",
    "del train_lr_data, validation_lr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400ada32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/3: 100%|██████████| 30/30 [01:00<00:00,  2.01s/it]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 39 out of 146\n",
      "['home_ownership_status_MORTGAGE', 'home_ownership_status_OWN', 'state_CO', 'state_FL', 'state_GA', 'state_IL', 'state_NV', 'state_NY', 'state_OR', 'state_SC', 'state_WA', 'income_verification_status_Not Verified', 'income_verification_status_Verified', 'loan_purpose_credit_card', 'loan_purpose_other', 'loan_purpose_infrequent_sklearn', 'director', 'driver', 'engineer', 'owner', 'sales', 'business', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'total_credit_lines', 'revolving_balance', 'active_revolving_trades', 'months_since_oldest_revolving', 'total_installment_credit_limit', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'inquiries_last_6months', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_bankcard_limit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_lr(\n",
    "    X,\n",
    "    y,\n",
    "    n_splits=3,\n",
    "    n_boot=10,\n",
    "    subsample=0.7,\n",
    "    alpha=1e-5,\n",
    "    l1_ratio=0.5,\n",
    "    threshold=0.75,\n",
    "    max_iter=5,\n",
    "    tol=1e-3,\n",
    "    random_state=34,\n",
    "    class_weight=\"balanced\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Efficient stability selection for feature selection using ElasticNet logistic regression via SGD.\n",
    "\n",
    "    Selects features that are nonzero in at least `threshold` fraction of runs (cross-validation × bootstraps).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_idx : np.ndarray\n",
    "        Indices of features selected.\n",
    "    freq : np.ndarray\n",
    "        Fraction of times each feature was selected (between 0 and 1).\n",
    "    \"\"\"\n",
    "    if hasattr(y, \"to_numpy\"):\n",
    "        y = y.to_numpy().ravel()\n",
    "    else:\n",
    "        y = np.asarray(y).ravel()\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    counts = np.zeros(n_features, dtype=np.int32)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    total_runs = n_splits * n_boot\n",
    "    progress_bar = tqdm(total=total_runs, desc=\"LR Feature Selection\", leave=True)\n",
    "\n",
    "    run = 0\n",
    "    for fold_index, (tr_idx, _) in enumerate(skf.split(np.zeros_like(y), y), start=1):\n",
    "        X_fold = X[tr_idx]\n",
    "        y_fold = y[tr_idx]\n",
    "        n_fold = len(tr_idx)\n",
    "\n",
    "        for _ in range(n_boot):\n",
    "            run += 1\n",
    "            m = int(subsample * n_fold)\n",
    "            sub_local = rng.choice(n_fold, size=m, replace=False)\n",
    "\n",
    "            X_sub = X_fold[sub_local]\n",
    "            y_sub = y_fold[sub_local]\n",
    "\n",
    "            classifier = SGDClassifier(\n",
    "                loss=\"log_loss\",\n",
    "                penalty=\"elasticnet\",\n",
    "                alpha=alpha,\n",
    "                l1_ratio=l1_ratio,\n",
    "                max_iter=max_iter,\n",
    "                tol=tol,\n",
    "                class_weight=class_weight,\n",
    "                random_state=random_state + 1000 * fold_index + run,\n",
    "            )\n",
    "            classifier.fit(X_sub, y_sub)\n",
    "\n",
    "            counts += classifier.coef_.ravel() != 0\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_description(f\"Fold {fold_index}/{n_splits}\")\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    frequency = counts / float(total_runs)\n",
    "    selected_indices = np.flatnonzero(frequency >= threshold)\n",
    "    return selected_indices, frequency\n",
    "\n",
    "\n",
    "# we are only using the train data for feature selection\n",
    "selected_indices, frequency = feature_selection_lr(\n",
    "    X_train_lr,\n",
    "    y_train_lr,\n",
    "    n_splits=3,  # 3 is usually enough and faster than 5\n",
    "    n_boot=10,  # start with 10; increase to 20 if selection is too noisy\n",
    "    subsample=0.7,\n",
    "    alpha=3e-4,  # increase (e.g., 3e-4) to select fewer features; decrease to select more\n",
    "    l1_ratio=0.85,\n",
    "    threshold=0.9,  # increase to be stricter (fewer features), decrease to include more\n",
    "    max_iter=5,\n",
    "    tol=1e-3,\n",
    "    random_state=34,\n",
    ")\n",
    "\n",
    "print(\"Selected features:\", selected_indices.size, \"out of\", X_train_lr.shape[1])\n",
    "selected_features_lr = [stable_features[i] for i in selected_indices]\n",
    "print(selected_features_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bf9ee",
   "metadata": {},
   "source": [
    "By applying this feature selection method, we were able to reduce the number of features from almost 200 to approximately 40. This substantial reduction makes the model lighter and more efficient, since it focuses only on the most relevant predictors. \n",
    "\n",
    "This helps us in several ways:\n",
    "- The model is less likely to overfit, which means we can expect it to generalize better to new, unseen data and to behave more consistently.\n",
    "- With fewer features, the model becomes easier to interpret, allowing us to better understand the drivers of predictions and communicate results to stakeholders.\n",
    "- A more compact feature set simplifies initial model monitoring after deployment, making it easier to identify issues, track changes, and validate assumptions in production.\n",
    "\n",
    "Overall, careful feature selection increases our confidence in building a robust, reliable, and maintainable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18bc68f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lr_home_ownership_status_MORTGAGE', 'lr_home_ownership_status_OWN', 'lr_state_CO', 'lr_state_FL', 'lr_state_GA', 'lr_state_IL', 'lr_state_NV', 'lr_state_NY', 'lr_state_OR', 'lr_state_SC', 'lr_state_WA', 'lr_income_verification_status_Not Verified', 'lr_income_verification_status_Verified', 'lr_loan_purpose_credit_card', 'lr_loan_purpose_other', 'lr_loan_purpose_infrequent_sklearn', 'lr_director', 'lr_driver', 'lr_engineer', 'lr_owner', 'lr_sales', 'lr_business', 'lr_annual_income', 'lr_loan_amount_requested', 'lr_fico_score_high', 'lr_total_credit_lines', 'lr_revolving_balance', 'lr_active_revolving_trades', 'lr_months_since_oldest_revolving', 'lr_total_installment_credit_limit', 'lr_bankcard_open_to_buy', 'lr_months_since_recent_bankcard', 'lr_percent_bankcard_over_75pct_limit', 'lr_inquiries_last_6months', 'lr_months_since_recent_inquiry', 'lr_accounts_opened_past_12months', 'lr_accounts_opened_past_24months', 'lr_total_high_credit_limit', 'lr_total_bankcard_limit']\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.391658\n",
      "         Iterations 7\n",
      "Training time: 2.56 seconds\n",
      "\n",
      "Validation AUC: 0.6738\n"
     ]
    }
   ],
   "source": [
    "lr_data = pd.read_parquet(\"../data/lr_processed_data.parquet\")\n",
    "\n",
    "lr_features_renamed = {f: f\"lr_{f}\" for f in selected_features_lr}\n",
    "print(list(lr_features_renamed.values()))\n",
    "\n",
    "lr_data = lr_data.rename(columns=lr_features_renamed)\n",
    "X_train_df = lr_data[lr_data[\"dataset\"] == \"train\"][list(lr_features_renamed.values())]\n",
    "X_validation_df = lr_data[lr_data[\"dataset\"] == \"validation\"][list(lr_features_renamed.values())]\n",
    "y_train = lr_data[lr_data[\"dataset\"] == \"train\"][\"default_binary\"]\n",
    "y_validation = lr_data[lr_data[\"dataset\"] == \"validation\"][\"default_binary\"]\n",
    "\n",
    "del lr_data\n",
    "\n",
    "X_train = sm.add_constant(X_train_df[list(lr_features_renamed.values())])\n",
    "X_validation = sm.add_constant(X_validation_df[list(lr_features_renamed.values())])\n",
    "\n",
    "start_time = time.time()\n",
    "logit_model = sm.Logit(y_train_lr, X_train)\n",
    "lr_model = logit_model.fit()\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "validation_predicted = lr_model.predict(X_validation)\n",
    "validation_auc = roc_auc_score(y_validation_lr, validation_predicted)\n",
    "print(f\"\\nValidation AUC: {validation_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd21ab3",
   "metadata": {},
   "source": [
    "At this point, you might be wondering: \"Why is the AUC value comparatively low?\" The reason is that different problems with varying levels of complexity have different expected results. While with simpler datasets we could easily achieve metrics above 0.9, in this case, the current value is already considered reasonable given the problem's difficulty.\n",
    "\n",
    "It is important to note that AUC itself is not the ultimate metric here, but it does provide a good indication of how well the model ranks predictions. This property is particularly valuable, as it translates into actionable insights for the business: if a model can rank well, it empowers us to work with different score bands to make more informed lending decisions, such as how much to lend, to whom, and under what conditions. This makes the model's output not just a number, but a practical guide for real-world decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d30e80",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7dba8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data = pd.read_parquet(\"../data/xgb_processed_data.parquet\")\n",
    "\n",
    "train_xgb_data = xgb_data[xgb_data[\"dataset\"] == \"train\"]\n",
    "validation_xgb_data = xgb_data[xgb_data[\"dataset\"] == \"validation\"]\n",
    "\n",
    "del xgb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1915b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant features dropped: ['home_ownership_status_infrequent_sklearn', 'painter', 'pilot', 'stocker', 'business_loan', 'card_refi', 'cc_consolidation', 'citi', 'engagement', 'engagement_ring', 'motorcycle', 'pay_bills', 'pool', 'pool_loan', 'refinance_loan', 'restaurant', 'ring', 'small_business']\n",
      "Features before constant filtering: 196\n",
      "Features after constant filtering: 178\n"
     ]
    }
   ],
   "source": [
    "non_constant_features, dropped_features, selector = drop_constant_features(\n",
    "    train_xgb_data, feature_names, missing_values=\"include\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f74add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 147\n"
     ]
    }
   ],
   "source": [
    "top_correlation_pairs = get_top_correlation_pairs(train_xgb_data, non_constant_features)\n",
    "clusters = get_high_correlation_clusters(top_correlation_pairs, threshold=0.8)\n",
    "clusters_enriched = enrich_clusters_with_target_correlation(\n",
    "    clusters, train_xgb_data, target_column=\"default_binary\", correlation_method=\"kendall\"\n",
    ")\n",
    "non_correlated_features = [\n",
    "    feature\n",
    "    for feature in non_constant_features\n",
    "    if feature not in sum(clusters_enriched[\"removed_features\"].tolist(), [])\n",
    "]\n",
    "print(len(non_constant_features), len(non_correlated_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f51cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with high PSI drift: []\n",
      "Features before PSI filtering: 147\n",
      "Features after PSI filtering: 147\n"
     ]
    }
   ],
   "source": [
    "population_stable_features, drifted_features, drop_psi = get_population_stable_features(\n",
    "    train_xgb_data, non_correlated_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7719b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stable features: ['home_ownership_status_MORTGAGE', 'home_ownership_status_OWN', 'state_AL', 'state_AZ', 'state_CA', 'state_CO', 'state_CT', 'state_FL', 'state_GA', 'state_IL', 'state_IN', 'state_LA', 'state_MA', 'state_MD', 'state_MI', 'state_MN', 'state_MO', 'state_NC', 'state_NJ', 'state_NV', 'state_NY', 'state_OH', 'state_OR', 'state_PA', 'state_SC', 'state_TN', 'state_TX', 'state_VA', 'state_WA', 'state_WI', 'state_infrequent_sklearn', 'income_verification_status_Not Verified', 'income_verification_status_Source Verified', 'income_verification_status_Verified', 'loan_purpose_credit_card', 'loan_purpose_major_purchase', 'loan_purpose_other', 'loan_purpose_infrequent_sklearn', 'accountant', 'administrator', 'analyst', 'architect', 'attorney', 'bartender', 'bus', 'business_analyst', 'cashier', 'chef', 'clerk', 'cna', 'controller', 'cook', 'dealer', 'developer', 'director', 'driver', 'engineer', 'firefighter', 'operator', 'owner', 'pastor', 'physician', 'police', 'president', 'product', 'professor', 'program_manager', 'project', 'receptionist', 'sales', 'senior', 'server', 'software', 'software_engineer', 'sr', 'systems', 'teacher', 'truck', 'university', 'vice', 'vp', 'welder', 'bills', 'business', 'buying', 'car', 'card_consolidation', 'card_debt', 'card_payoff', 'card_refinance', 'cc', 'consolidate', 'consolidation_loan', 'debt_consolidation', 'debt_free', 'expenses', 'home', 'loan', 'moving', 'payoff', 'refi', 'refinance', 'employment_length_years', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'debt_to_income_ratio', 'delinquencies_past_2years', 'accounts_currently_delinquent', 'delinquent_amount', 'accounts_30days_past_due', 'accounts_120days_past_due', 'accounts_90plus_days_past_due_24m', 'accounts_ever_120days_past_due', 'public_records_count', 'public_records_bankruptcies', 'tax_liens_count', 'open_credit_lines', 'total_credit_lines', 'revolving_balance', 'revolving_utilization_rate', 'revolving_accounts_count', 'open_revolving_trades', 'active_revolving_trades', 'months_since_oldest_revolving', 'months_since_recent_revolving', 'installment_accounts_count', 'months_since_oldest_installment', 'total_installment_credit_limit', 'bankcard_accounts_count', 'active_bankcard_accounts', 'satisfactory_bankcard_accounts', 'bankcard_utilization', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'inquiries_last_6months', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_balance_excluding_mortgage', 'total_bankcard_limit', 'average_current_balance', 'months_since_recent_account', 'mortgage_accounts_count', 'percent_trades_never_delinquent']\n",
      "Time non-stable features: []\n"
     ]
    }
   ],
   "source": [
    "time_stable_features, time_nonstable_features, adf_results = select_time_stable_features(\n",
    "    train_xgb_data, population_stable_features, date_column=\"loan_issue_date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccd83c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home_ownership_status_MORTGAGE', 'home_ownership_status_OWN', 'state_AL', 'state_AZ', 'state_CA', 'state_CO', 'state_CT', 'state_FL', 'state_GA', 'state_IL', 'state_IN', 'state_LA', 'state_MA', 'state_MD', 'state_MI', 'state_MN', 'state_MO', 'state_NC', 'state_NJ', 'state_NV', 'state_NY', 'state_OH', 'state_OR', 'state_PA', 'state_SC', 'state_TN', 'state_TX', 'state_VA', 'state_WA', 'state_WI', 'state_infrequent_sklearn', 'income_verification_status_Not Verified', 'income_verification_status_Source Verified', 'income_verification_status_Verified', 'loan_purpose_credit_card', 'loan_purpose_major_purchase', 'loan_purpose_other', 'loan_purpose_infrequent_sklearn', 'accountant', 'administrator', 'analyst', 'architect', 'attorney', 'bartender', 'bus', 'business_analyst', 'cashier', 'chef', 'clerk', 'cna', 'controller', 'cook', 'dealer', 'developer', 'director', 'driver', 'engineer', 'firefighter', 'operator', 'owner', 'pastor', 'physician', 'police', 'president', 'product', 'professor', 'program_manager', 'project', 'receptionist', 'sales', 'senior', 'server', 'software', 'software_engineer', 'sr', 'systems', 'teacher', 'truck', 'university', 'vice', 'vp', 'welder', 'bills', 'business', 'buying', 'car', 'card_consolidation', 'card_debt', 'card_payoff', 'card_refinance', 'cc', 'consolidate', 'consolidation_loan', 'debt_consolidation', 'debt_free', 'expenses', 'home', 'loan', 'moving', 'payoff', 'refi', 'refinance', 'employment_length_years', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'debt_to_income_ratio', 'delinquencies_past_2years', 'accounts_currently_delinquent', 'delinquent_amount', 'accounts_30days_past_due', 'accounts_120days_past_due', 'accounts_90plus_days_past_due_24m', 'accounts_ever_120days_past_due', 'public_records_count', 'public_records_bankruptcies', 'tax_liens_count', 'open_credit_lines', 'total_credit_lines', 'revolving_balance', 'revolving_utilization_rate', 'revolving_accounts_count', 'open_revolving_trades', 'active_revolving_trades', 'months_since_oldest_revolving', 'months_since_recent_revolving', 'installment_accounts_count', 'months_since_oldest_installment', 'total_installment_credit_limit', 'bankcard_accounts_count', 'active_bankcard_accounts', 'satisfactory_bankcard_accounts', 'bankcard_utilization', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'inquiries_last_6months', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_balance_excluding_mortgage', 'total_bankcard_limit', 'average_current_balance', 'months_since_recent_account', 'mortgage_accounts_count', 'percent_trades_never_delinquent']\n"
     ]
    }
   ],
   "source": [
    "stable_features = time_stable_features\n",
    "print(stable_features)\n",
    "target = \"default_binary\"\n",
    "\n",
    "X_train_xgb = train_xgb_data[stable_features].to_numpy()\n",
    "X_validation_xgb = validation_xgb_data[stable_features].to_numpy()\n",
    "\n",
    "y_train_xgb = train_xgb_data[target]\n",
    "y_validation_xgb = validation_xgb_data[target]\n",
    "\n",
    "del train_xgb_data, validation_xgb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11aebaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employment_length_years', 'annual_income', 'loan_amount_requested', 'fico_score_high', 'debt_to_income_ratio', 'total_credit_lines', 'revolving_balance', 'revolving_utilization_rate', 'revolving_accounts_count', 'months_since_oldest_revolving', 'months_since_oldest_installment', 'total_installment_credit_limit', 'satisfactory_bankcard_accounts', 'bankcard_utilization', 'bankcard_open_to_buy', 'months_since_recent_bankcard', 'percent_bankcard_over_75pct_limit', 'months_since_recent_inquiry', 'accounts_opened_past_12months', 'accounts_opened_past_24months', 'total_high_credit_limit', 'total_balance_excluding_mortgage', 'total_bankcard_limit', 'average_current_balance', 'mortgage_accounts_count', 'percent_trades_never_delinquent']\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_xgb(\n",
    "    X,\n",
    "    y,\n",
    "    feature_names,\n",
    "    n_boot=10,\n",
    "    subsample=0.7,\n",
    "    threshold=0.7,\n",
    "    boruta_percentile=80,\n",
    "    boruta_pvalue=0.1,\n",
    "    random_state=34,\n",
    "    xgb_params=None,\n",
    "    n_trials=30,\n",
    "    sample_size=10_000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stability selection for feature selection using BorutaShap with bootstrap strategy.\n",
    "\n",
    "    For each bootstrap, runs BorutaShap and counts inclusion frequency per feature.\n",
    "    Selects features kept in at least `threshold` fraction of runs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_features: list\n",
    "        Features selected by stability selection with BorutaShap.\n",
    "    frequency: pd.Series\n",
    "        Fraction of times each feature was selected (indexed by feature name).\n",
    "    \"\"\"\n",
    "    if hasattr(y, \"to_numpy\"):\n",
    "        y = y.to_numpy().ravel()\n",
    "    else:\n",
    "        y = np.asarray(y).ravel()\n",
    "\n",
    "    if X.shape[0] > sample_size:\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, train_size=sample_size, random_state=random_state)\n",
    "        idx, _ = next(sss.split(X, y))\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    counts = np.zeros(n_features, dtype=np.int32)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    total_runs = n_boot\n",
    "    progress_bar = tqdm(total=total_runs, desc=\"BorutaShap Stability Selection\", leave=True)\n",
    "\n",
    "    if xgb_params is None:\n",
    "        xgb_estimator = xgb.XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.08,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=1.0,\n",
    "            reg_alpha=0.0,\n",
    "            eval_metric=\"auc\",\n",
    "            device=\"cuda\",\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "    else:\n",
    "        xgb_estimator = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    for boot in range(n_boot):\n",
    "        m = int(subsample * n_samples)\n",
    "        sub_local = rng.choice(n_samples, size=m, replace=False)\n",
    "        X_sub = X[sub_local]\n",
    "        y_sub = y[sub_local]\n",
    "\n",
    "        # BorutaShap expects pandas DataFrame\n",
    "        if hasattr(X_sub, \"toarray\"):\n",
    "            X_df = pd.DataFrame(X_sub.toarray(), columns=feature_names)\n",
    "        else:\n",
    "            X_df = pd.DataFrame(X_sub, columns=feature_names)\n",
    "\n",
    "        boruta_selector = BorutaShap(\n",
    "            model=xgb_estimator,\n",
    "            importance_measure=\"shap\",\n",
    "            classification=True,\n",
    "            percentile=boruta_percentile,\n",
    "            pvalue=boruta_pvalue,\n",
    "        )\n",
    "\n",
    "        boruta_selector.fit(\n",
    "            X=X_df,\n",
    "            y=y_sub,\n",
    "            sample=False,\n",
    "            train_or_test=\"train\",\n",
    "            n_trials=n_trials,\n",
    "            random_state=random_state + boot,\n",
    "        )\n",
    "\n",
    "        boruta_selector.TentativeRoughFix()\n",
    "\n",
    "        features_removed = boruta_selector.features_to_remove\n",
    "        selected = ~np.isin(feature_names, features_removed)\n",
    "        counts += selected.astype(np.int32)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f\"Bootstrap {boot+1}/{n_boot}\")\n",
    "\n",
    "    progress_bar.close()\n",
    "    frequency = counts / float(total_runs)\n",
    "    selected_features = [feature_names[i] for i, freq in enumerate(frequency) if freq >= threshold]\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    return selected_features, pd.Series(frequency, index=feature_names)\n",
    "\n",
    "\n",
    "selected_features_xgb, frequency_borutashap = feature_selection_xgb(\n",
    "    X_train_xgb,\n",
    "    y_train_xgb,\n",
    "    feature_names=stable_features,\n",
    ")\n",
    "print(selected_features_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d87da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xgb_employment_length_years', 'xgb_annual_income', 'xgb_loan_amount_requested', 'xgb_fico_score_high', 'xgb_debt_to_income_ratio', 'xgb_total_credit_lines', 'xgb_revolving_balance', 'xgb_revolving_utilization_rate', 'xgb_revolving_accounts_count', 'xgb_months_since_oldest_revolving', 'xgb_months_since_oldest_installment', 'xgb_total_installment_credit_limit', 'xgb_satisfactory_bankcard_accounts', 'xgb_bankcard_utilization', 'xgb_bankcard_open_to_buy', 'xgb_months_since_recent_bankcard', 'xgb_percent_bankcard_over_75pct_limit', 'xgb_months_since_recent_inquiry', 'xgb_accounts_opened_past_12months', 'xgb_accounts_opened_past_24months', 'xgb_total_high_credit_limit', 'xgb_total_balance_excluding_mortgage', 'xgb_total_bankcard_limit', 'xgb_average_current_balance', 'xgb_mortgage_accounts_count', 'xgb_percent_trades_never_delinquent']\n",
      "Training time: 5.27 seconds\n",
      "\n",
      "Validation AUC: 0.6873\n"
     ]
    }
   ],
   "source": [
    "xgb_data = pd.read_parquet(\"../data/xgb_processed_data.parquet\")\n",
    "\n",
    "xgb_features_renamed = {f: f\"xgb_{f}\" for f in selected_features_xgb}\n",
    "print(list(xgb_features_renamed.values()))\n",
    "\n",
    "xgb_data = xgb_data.rename(columns=xgb_features_renamed)\n",
    "X_train_df = xgb_data[xgb_data[\"dataset\"] == \"train\"][list(xgb_features_renamed.values())]\n",
    "X_validation_df = xgb_data[xgb_data[\"dataset\"] == \"validation\"][list(xgb_features_renamed.values())]\n",
    "y_train = xgb_data[xgb_data[\"dataset\"] == \"train\"][\"default_binary\"]\n",
    "y_validation = xgb_data[xgb_data[\"dataset\"] == \"validation\"][\"default_binary\"]\n",
    "\n",
    "del xgb_data\n",
    "\n",
    "X_train = X_train_df[list(xgb_features_renamed.values())]\n",
    "X_validation = X_validation_df[list(xgb_features_renamed.values())]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    eval_metric=\"auc\",\n",
    "    n_jobs=-1,\n",
    "    device=\"cuda\",\n",
    "    random_state=34,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "validation_predicted = xgb_model.predict_proba(X_validation)[:, 1]\n",
    "validation_auc = roc_auc_score(y_validation, validation_predicted)\n",
    "print(f\"\\nValidation AUC: {validation_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872cc15",
   "metadata": {},
   "source": [
    "With a more competitive model like XGBoost, we achieved an AUC increase of 0.01. While this may not seem significant, it is important to note two things: no dedicated hyperparameter tuning was performed for this model, which could potentially boost AUC to around 0.7, and even this current improvement might lead to valuable results that we will explore in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9c651",
   "metadata": {},
   "source": [
    "# Persist datasets and predictions\n",
    "\n",
    "Nós já temos as variáveis iniciais selecionadas (já filtradas para serem o mais estável possível)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22422bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1059906, 96)\n",
      "['xgb_employment_length_years', 'xgb_annual_income', 'xgb_loan_amount_requested', 'xgb_fico_score_high', 'xgb_debt_to_income_ratio', 'xgb_total_credit_lines', 'xgb_revolving_balance', 'xgb_revolving_utilization_rate', 'xgb_revolving_accounts_count', 'xgb_months_since_oldest_revolving', 'xgb_months_since_oldest_installment', 'xgb_total_installment_credit_limit', 'xgb_satisfactory_bankcard_accounts', 'xgb_bankcard_utilization', 'xgb_bankcard_open_to_buy', 'xgb_months_since_recent_bankcard', 'xgb_percent_bankcard_over_75pct_limit', 'xgb_months_since_recent_inquiry', 'xgb_accounts_opened_past_12months', 'xgb_accounts_opened_past_24months', 'xgb_total_high_credit_limit', 'xgb_total_balance_excluding_mortgage', 'xgb_total_bankcard_limit', 'xgb_average_current_balance', 'xgb_mortgage_accounts_count', 'xgb_percent_trades_never_delinquent']\n",
      "(1059906, 122)\n",
      "['lr_home_ownership_status_MORTGAGE', 'lr_home_ownership_status_OWN', 'lr_state_CO', 'lr_state_FL', 'lr_state_GA', 'lr_state_IL', 'lr_state_NV', 'lr_state_NY', 'lr_state_OR', 'lr_state_SC', 'lr_state_WA', 'lr_income_verification_status_Not Verified', 'lr_income_verification_status_Verified', 'lr_loan_purpose_credit_card', 'lr_loan_purpose_other', 'lr_loan_purpose_infrequent_sklearn', 'lr_director', 'lr_driver', 'lr_engineer', 'lr_owner', 'lr_sales', 'lr_business', 'lr_annual_income', 'lr_loan_amount_requested', 'lr_fico_score_high', 'lr_total_credit_lines', 'lr_revolving_balance', 'lr_active_revolving_trades', 'lr_months_since_oldest_revolving', 'lr_total_installment_credit_limit', 'lr_bankcard_open_to_buy', 'lr_months_since_recent_bankcard', 'lr_percent_bankcard_over_75pct_limit', 'lr_inquiries_last_6months', 'lr_months_since_recent_inquiry', 'lr_accounts_opened_past_12months', 'lr_accounts_opened_past_24months', 'lr_total_high_credit_limit', 'lr_total_bankcard_limit']\n",
      "(1059906, 161)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_amount_funded</th>\n",
       "      <th>loan_amount_funded_investors</th>\n",
       "      <th>loan_term_months</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>monthly_payment</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_subgrade</th>\n",
       "      <th>employment_title</th>\n",
       "      <th>home_ownership_status</th>\n",
       "      <th>...</th>\n",
       "      <th>lr_months_since_recent_bankcard</th>\n",
       "      <th>lr_percent_bankcard_over_75pct_limit</th>\n",
       "      <th>lr_inquiries_last_6months</th>\n",
       "      <th>lr_months_since_recent_inquiry</th>\n",
       "      <th>lr_accounts_opened_past_12months</th>\n",
       "      <th>lr_accounts_opened_past_24months</th>\n",
       "      <th>lr_total_high_credit_limit</th>\n",
       "      <th>lr_total_bankcard_limit</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>lr_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>RENT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>0.143411</td>\n",
       "      <td>0.136394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077175</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>RENT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>0.157012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1076863</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>RENT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>0.139291</td>\n",
       "      <td>0.183439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075269</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>156.46</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>Veolia Transportaton</td>\n",
       "      <td>RENT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>0.088156</td>\n",
       "      <td>0.185711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1072053</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>109.43</td>\n",
       "      <td>E</td>\n",
       "      <td>E1</td>\n",
       "      <td>MKC Accounting</td>\n",
       "      <td>RENT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>0.214369</td>\n",
       "      <td>0.184568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id  loan_amount_funded  loan_amount_funded_investors  \\\n",
       "0  1077501              5000.0                        4975.0   \n",
       "1  1077175              2400.0                        2400.0   \n",
       "2  1076863             10000.0                       10000.0   \n",
       "3  1075269              5000.0                        5000.0   \n",
       "4  1072053              3000.0                        3000.0   \n",
       "\n",
       "   loan_term_months  interest_rate  monthly_payment loan_grade loan_subgrade  \\\n",
       "0                36         0.1065           162.87          B            B2   \n",
       "1                36         0.1596            84.33          C            C5   \n",
       "2                36         0.1349           339.31          C            C1   \n",
       "3                36         0.0790           156.46          A            A4   \n",
       "4                36         0.1864           109.43          E            E1   \n",
       "\n",
       "       employment_title home_ownership_status  ...  \\\n",
       "0                  <NA>                  RENT  ...   \n",
       "1                  <NA>                  RENT  ...   \n",
       "2   AIR RESOURCES BOARD                  RENT  ...   \n",
       "3  Veolia Transportaton                  RENT  ...   \n",
       "4       MKC Accounting                   RENT  ...   \n",
       "\n",
       "  lr_months_since_recent_bankcard lr_percent_bankcard_over_75pct_limit  \\\n",
       "0                        0.020344                                  0.5   \n",
       "1                        0.020344                                  0.5   \n",
       "2                        0.020344                                  0.5   \n",
       "3                        0.020344                                  0.5   \n",
       "4                        0.020344                                  0.5   \n",
       "\n",
       "  lr_inquiries_last_6months lr_months_since_recent_inquiry  \\\n",
       "0                     0.125                            0.2   \n",
       "1                     0.250                            0.2   \n",
       "2                     0.125                            0.2   \n",
       "3                     0.375                            0.2   \n",
       "4                     0.250                            0.2   \n",
       "\n",
       "  lr_accounts_opened_past_12months lr_accounts_opened_past_24months  \\\n",
       "0                           0.0625                           0.0625   \n",
       "1                           0.0625                           0.0625   \n",
       "2                           0.0625                           0.0625   \n",
       "3                           0.0625                           0.0625   \n",
       "4                           0.0625                           0.0625   \n",
       "\n",
       "  lr_total_high_credit_limit lr_total_bankcard_limit  xgb_pred   lr_pred  \n",
       "0                   0.711753                0.686046  0.143411  0.136394  \n",
       "1                   0.711753                0.686046  0.193209  0.157012  \n",
       "2                   0.711753                0.686046  0.139291  0.183439  \n",
       "3                   0.711753                0.686046  0.088156  0.185711  \n",
       "4                   0.711753                0.686046  0.214369  0.184568  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_data = pd.read_parquet(\"../data/xgb_processed_data.parquet\")\n",
    "\n",
    "data = xgb_data.drop(columns=feature_names)\n",
    "print(data.shape)\n",
    "\n",
    "xgb_features_renamed = {f: f\"xgb_{f}\" for f in selected_features_xgb}\n",
    "print(list(xgb_features_renamed.values()))\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    xgb_data[[\"loan_id\"] + selected_features_xgb].rename(columns=xgb_features_renamed),\n",
    "    on=\"loan_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "print(data.shape)\n",
    "\n",
    "del xgb_data\n",
    "\n",
    "lr_data = pd.read_parquet(\"../data/lr_processed_data.parquet\")\n",
    "\n",
    "lr_features_renamed = {f: f\"lr_{f}\" for f in selected_features_lr}\n",
    "print(list(lr_features_renamed.values()))\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    lr_data[[\"loan_id\"] + selected_features_lr].rename(columns=lr_features_renamed),\n",
    "    on=\"loan_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "print(data.shape)\n",
    "\n",
    "del lr_data\n",
    "\n",
    "data[\"xgb_pred\"] = xgb_model.predict_proba(data[list(xgb_features_renamed.values())].to_numpy())[:, 1]\n",
    "data[\"lr_pred\"] = lr_model.predict(sm.add_constant(data[list(lr_features_renamed.values())]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "695f2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(\"../data/scored_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
